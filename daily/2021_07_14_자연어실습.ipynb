{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021_07_14_자연어실습.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/risker93/Hello_World/blob/main/daily/2021_07_14_%E1%84%8C%E1%85%A1%E1%84%8B%E1%85%A7%E1%86%AB%E1%84%8B%E1%85%A5%E1%84%89%E1%85%B5%E1%86%AF%E1%84%89%E1%85%B3%E1%86%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrOYEB2RbG0l"
      },
      "source": [
        "RNN의 문제점\n",
        "- 연산량이 크다.\n",
        "- 기울기 소실 (정보손실)\n",
        "- 번역에는 사용하기 힘들다.  \n",
        "나는 점심을 먹는다.  \n",
        "i eat lunch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raxjClipRjrE"
      },
      "source": [
        "## seq2seq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3OkVAVwpksG"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCidfPcXqoSu"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5RMwEPsRfSG"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.lstm = tf.keras.layers.LSTM(enc_units) # return_sequences 매개변수 False전달\n",
        "  def call(self, x):\n",
        "    print(\"입력 shape:\", x.shape)\n",
        "\n",
        "    x = self.embedding(x)\n",
        "    print(\"Embedding Layer를 거친 shape \", x.shape)\n",
        "\n",
        "    output = self.lstm(x)\n",
        "    print(\"LSTM shape의 output shape:\", output.shape)\n",
        "\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YFOzXCyriz3",
        "outputId": "be6d2f20-b774-4986-97a2-89b731838c24"
      },
      "source": [
        "vocab_size = 30000\n",
        "emb_size = 256\n",
        "lstm_size = 512\n",
        "batch_size = 1\n",
        "sample_seq_len = 3\n",
        "\n",
        "print(\"Vocab Size : {0}\".format(vocab_size))\n",
        "print(\"Embedding Size : {0}\".format(emb_size))\n",
        "print(\"LSTM Size : {0}\".format(lstm_size))\n",
        "print(\"Batch Size : {0}\".format(batch_size))\n",
        "print(\"Sample Sequence Length : {0}\\n\".format(sample_seq_len))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab Size : 30000\n",
            "Embedding Size : 256\n",
            "LSTM Size : 512\n",
            "Batch Size : 1\n",
            "Sample Sequence Length : 3\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6S1rICOZsUA3",
        "outputId": "ee3ab4e3-7272-4dc8-b1bd-999185dada72"
      },
      "source": [
        "encoder = Encoder(vocab_size, emb_size, lstm_size)\n",
        "sample_input = tf.zeros((batch_size, sample_seq_len)) # (1,3)\n",
        "\n",
        "sample_output = encoder(sample_input)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "입력 shape: (1, 3)\n",
            "Embedding Layer를 거친 shape  (1, 3, 256)\n",
            "LSTM shape의 output shape: (1, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOmx8JXNtWRe"
      },
      "source": [
        "![](https://aiffelstaticprd.blob.core.windows.net/media/images/GN-4-L-6.max-800x600.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiRIw7A9tyfe"
      },
      "source": [
        "### LSTM Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ai7Li7pls1vj"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.lstm = tf.keras.layers.LSTM(dec_units, return_sequences=True)\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "    self.softmax = tf.keras.layers.Softmax(axis=-1)\n",
        "  \n",
        "  def call(self, x, context_v):\n",
        "    print(\"입력 shape:\", x.shape)\n",
        "\n",
        "    x = self.embedding(x)\n",
        "    print(\"Embedding Layer을 거친 Shape:\", x.shape)\n",
        "\n",
        "    context_v = tf.repeat(tf.expand_dims(context_v, axis=1), repeats=x.shape[1], axis=1)\n",
        "    x = tf.concat([x, context_v], axis= -1)\n",
        "    print(\"Context Vector가 더해진 shape :\", x.shape)\n",
        "\n",
        "    x = self.lstm(x)\n",
        "    print(\"LSTM Layer의 Output shape:\", x.shape)\n",
        "\n",
        "    output = self.fc(x)\n",
        "    print(\"Decoder의 최종 Output shape:\", output.shape)\n",
        "    \n",
        "    return self.softmax(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Vn8LuUOvHRP",
        "outputId": "ce37561f-af54-4251-cf58-dd17e165c969"
      },
      "source": [
        "print(\"vocab size : {0}\".format(vocab_size))\n",
        "print(\"Embedding Size : {0}\".format(emb_size))\n",
        "print(\"LSTM size : {0}\".format(lstm_size))\n",
        "print(\"Batch size : {0}\".format(batch_size))\n",
        "print(\"Sample Sequence Length : {0}\".format(sample_seq_len))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size : 30000\n",
            "Embedding Size : 256\n",
            "LSTM size : 512\n",
            "Batch size : 1\n",
            "Sample Sequence Length : 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkU3z-h5vztX",
        "outputId": "0e1b4c2d-a35a-4857-d1fb-1437e447f4db"
      },
      "source": [
        "decoder = Decoder(vocab_size, emb_size, lstm_size)\n",
        "sample_input = tf.zeros((batch_size, sample_seq_len))\n",
        "\n",
        "dec_output = decoder(sample_input, sample_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "입력 shape: (1, 3)\n",
            "Embedding Layer을 거친 Shape: (1, 3, 256)\n",
            "Context Vector가 더해진 shape : (1, 3, 768)\n",
            "LSTM Layer의 Output shape: (1, 3, 512)\n",
            "Decoder의 최종 Output shape: (1, 3, 30000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhxtGdtiwcqe"
      },
      "source": [
        "![](https://aiffelstaticprd.blob.core.windows.net/media/images/GN-4-L-7.max-800x600.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m_dJyXCwuOn"
      },
      "source": [
        "Rnn에 기반한 seq2seq모델의 2가지 문제점\n",
        "1. 기울기 소실\n",
        "2. 하나의 고정된 벡터에 모든 정보를 압축하려다 보니까 정보 손실이 발생"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyTXOtQkzVOn"
      },
      "source": [
        "## 어텐션 메커니즘 (Attention Mechanism)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4w-FX24F3EJ7"
      },
      "source": [
        "- 어텐션 아이디어는 디코더에서 출력 단어를 예측하는 매 시점(time step)마다 인코더에서 전체 입력 문장을 다시 한번 참고 한다는 점\n",
        "- 전체 입력 문장을 전부 다 동일한 비율로 참고하는 것이 아니라, 해당 시점에서 예측해야할 단어와 연관이 있는 입력 단어 부분을 좀 더 집중해서 보자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPh-3kKk0VEP"
      },
      "source": [
        "dict = {\"2017\" : \"Transformer\", \"2018\": \"Bert\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJl-Aldn3xz3",
        "outputId": "ac8877db-2ccf-4fe1-c618-162bb00d703d"
      },
      "source": [
        "print(dict[\"2017\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Transformer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-cxYiDSzkSG"
      },
      "source": [
        "![](https://wikidocs.net/images/page/22893/%EC%BF%BC%EB%A6%AC.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eolk6gU3873"
      },
      "source": [
        "Attention(Q, K, V) = Attention Value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9pjiKQM4Krn"
      },
      "source": [
        "```\n",
        "Q = Query : t시점의 디코더 셀에서의 은닉 상태\n",
        "K = Keys : 모든 시점의 인코더 셀의 은닉 상태들\n",
        "V = Values : 모든 시점의 인코더 셀의 은닉 상태들\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuJGCUlR4ilA"
      },
      "source": [
        "### 닷 프로덕트 어텐션(Dot-Product Attention)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izfMak3Czk--"
      },
      "source": [
        "![](https://wikidocs.net/images/page/22893/dotproductattention1_final.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1MHU4zs5NMH"
      },
      "source": [
        "### 어텐션 스코어 구하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hUwBuDGznim"
      },
      "source": [
        "![](https://wikidocs.net/images/page/22893/dotproductattention2_final.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_xXXCI_zqTm"
      },
      "source": [
        "$$score(s_t, h_i) = S_t^T h_i $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtMj-2BZz0Y-"
      },
      "source": [
        "$$e^t = [s_t^T h_1, ..., s_t^T h_N]$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgsysXq656_3"
      },
      "source": [
        "### 소프트맥스 함수를 통해 어텐션 분포를 구한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXdPcXO8z4df"
      },
      "source": [
        "![](https://wikidocs.net/images/page/22893/dotproductattention3_final.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNBtgPjbz7fe"
      },
      "source": [
        "$${\\alpha}^t = softmax(e^t)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvKQYbYF6P1H"
      },
      "source": [
        "### 각 인코더의 어텐션 가중치와 은닉상태를 가중합하여 어텐션 값(Attention Value)를 구한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFSWlZwQz9-m"
      },
      "source": [
        "![](https://wikidocs.net/images/page/22893/dotproductattention4_final.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_ZdqQdn0Awm"
      },
      "source": [
        "$$a_t = \\sum_{i=1}^{N}{{\\alpha}_i^th_i}$$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4o08CGZ666f"
      },
      "source": [
        "### 어텐션 값과 디코더의 t시점의 은닉 상태를 연결한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmNjDTCa0DyO"
      },
      "source": [
        "![](https://wikidocs.net/images/page/22893/dotproductattention5_final_final.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDWKF2ns7Nnf"
      },
      "source": [
        "### 출력층 연산의 입력이 되는 $\\tilde{s_t}$를 계산한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPkUlJ6Q0G8m"
      },
      "source": [
        "![](https://wikidocs.net/images/page/22893/st.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2R0YSEQ40JHH"
      },
      "source": [
        "$$ \\tilde{s_{t}}=tanh(W_c[a_t ; s_t] + b_c)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jED-5IC7wD_"
      },
      "source": [
        "### $\\tilde{s_t}$를 출력층의 입력으로 사용한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpnSuRZw0LqP"
      },
      "source": [
        "$$ \\hat{y_t}=Softmax(W_y\\tilde{s_t}+b_y)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XijDXw7MBuye"
      },
      "source": [
        "## Bahdanau Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGY3vHzB0PVH"
      },
      "source": [
        "- Bahdanau Attention\n",
        "$$ Score_{alignment} = W * tanh(W_{decoder} * H_{decoder} + W_{encoder} * H_{encoder}) $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYpZjxlFwRqm",
        "outputId": "0c88e13e-815c-49b9-df3d-5482161d1c21"
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W_decoder = tf.keras.layers.Dense(units)\n",
        "    self.W_encoder = tf.keras.layers.Dense(units)\n",
        "    self.W_combine = tf.keras.layers.Dense(1)\n",
        "  \n",
        "  def call(self, H_encoder, H_decoder):\n",
        "    print(\"[H_encoder] shape :\", H_encoder.shape)\n",
        "\n",
        "    H_encoder = self.W_encoder(H_encoder)\n",
        "    print(\"[W_encoder X H_encoder shape:\", H_encoder.shape)\n",
        "\n",
        "    print(\"\\n[H_decoder] shape: \", H_decoder.shape)\n",
        "    H_decoder = tf.expand_dims(H_decoder, 1)\n",
        "    H_decoder = self.W_decoder(H_decoder)\n",
        "\n",
        "    print(\"[W_decoder X H_decoder] shape:\", H_decoder.shape)\n",
        "\n",
        "    score = self.W_combine(tf.nn.tanh(H_decoder+H_encoder))\n",
        "    print(\"[Score Alignment] shape :\", score.shape)\n",
        "\n",
        "    attention_weights = tf.nn.softmax(score, axis = 1)\n",
        "    print(\"\\n 최종 weight : \\n\", attention_weights.numpy())\n",
        "\n",
        "    context_vector = attention_weights * H_decoder\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights\n",
        "  \n",
        "  W_size = 100\n",
        "\n",
        "  print(\"Hidden State를 {0}차원으로 Mapping \\n\".format(W_size))\n",
        "\n",
        "  attention = BahdanauAttention(W_size)\n",
        "\n",
        "  enc_state = tf.random.uniform((1, 10, 512))\n",
        "  dec_state = tf.random.uniform((1, 512))\n",
        "\n",
        "  _ = attention(enc_state, dec_state)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hidden State를 100차원으로 Mapping \n",
            "\n",
            "[H_encoder] shape : (1, 10, 512)\n",
            "[W_encoder X H_encoder shape: (1, 10, 100)\n",
            "\n",
            "[H_decoder] shape:  (1, 512)\n",
            "[W_decoder X H_decoder] shape: (1, 1, 100)\n",
            "[Score Alignment] shape : (1, 10, 1)\n",
            "\n",
            " 최종 weight : \n",
            " [[[0.08770792]\n",
            "  [0.16786946]\n",
            "  [0.09227852]\n",
            "  [0.09054877]\n",
            "  [0.07592397]\n",
            "  [0.16650593]\n",
            "  [0.06394071]\n",
            "  [0.0899744 ]\n",
            "  [0.11246318]\n",
            "  [0.05278726]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cgrb0cA2-r84"
      },
      "source": [
        "![](https://aiffelstaticprd.blob.core.windows.net/media/original_images/GN-4-L-9.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8maAEzHe_Myv"
      },
      "source": [
        "## Loung Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5O3TJZV0_PtY"
      },
      "source": [
        "$$ Score(H_{decoder}, H_{encoder}) = H_{decoder}^T*W_{combine}*H_{encoder}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpQNxkXI99Fa"
      },
      "source": [
        "class LuongAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(LuongAttention, self).__init__()\n",
        "    self.W_combine = tf.keras.layers.Dense(units)\n",
        "\n",
        "  def call(self, H_encoder, H_decoder):\n",
        "    print(\"[H_encoder] shape: \",H_encoder.shape)\n",
        "\n",
        "    WH = self.W_combine(H_encoder)\n",
        "    print(\"[W_encoder X H_encoder] shape: \", WH.shape)\n",
        "\n",
        "    H_decoder = tf.expand_dims(H_decoder, 1)\n",
        "    alignment = tf.matmul(WH, tf.transpose(H_decoder, [0, 2, 1]))\n",
        "    print(\"[Score_alignment] shape :\", alignment.shape)\n",
        "\n",
        "    attention_weights = tf.nn.softmax(alignment, axis = 1)\n",
        "    print(\"\\n최종 weight : \\n\", attention_weights.numpy())\n",
        "\n",
        "    attention_weights = tf.squeeze(attention_weights, axis= -1)\n",
        "    context_vector = tf.matmul(attention_weights, H_encoder)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8QYlUgZAzuC",
        "outputId": "1396327f-c4df-4d59-c728-46b7f44e9d3a"
      },
      "source": [
        "emb_size = 512\n",
        "attention = LuongAttention(emb_size)\n",
        "\n",
        "enc_state = tf.random.uniform((1, 10, emb_size))\n",
        "dec_state = tf.random.uniform((1, emb_size))\n",
        "\n",
        "_ = attention(enc_state, dec_state)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[H_encoder] shape:  (1, 10, 512)\n",
            "[W_encoder X H_encoder] shape:  (1, 10, 512)\n",
            "[Score_alignment] shape : (1, 10, 1)\n",
            "\n",
            "최종 weight : \n",
            " [[[3.3648440e-03]\n",
            "  [2.5860232e-01]\n",
            "  [2.2048462e-04]\n",
            "  [1.4769311e-02]\n",
            "  [1.8158993e-02]\n",
            "  [1.1614115e-04]\n",
            "  [6.6085684e-01]\n",
            "  [1.6638229e-03]\n",
            "  [4.2246096e-02]\n",
            "  [1.0583559e-06]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ryW5I_IaHM3"
      },
      "source": [
        "## 양방향 LSTM과 어텐션 메커니즘(IMDB리뷰 데이터)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OaOcwa8ap6h"
      },
      "source": [
        "### IMDB 리뷰 데이터 전처리 하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "di6H_zHEBKcY"
      },
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.utils import to_categorical \n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bv1E6asua5SX",
        "outputId": "d3bbe5e4-db07-40bf-fba6-a5f0f4979fc1"
      },
      "source": [
        "vocab_size = 10000\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTZa4Runa80C",
        "outputId": "5d5f3744-1030-482d-bab6-71cf797b2d20"
      },
      "source": [
        "print('리뷰의 최대 길이 : {}'.format(max(len(l) for l in x_train)))\n",
        "print('리뷰의 평균 길이 : {}'.format(sum(map(len, x_train))/len(x_train)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "리뷰의 최대 길이 : 2494\n",
            "리뷰의 평균 길이 : 238.71364\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHMNlSx6bP38"
      },
      "source": [
        "max_len = 500\n",
        "x_train = pad_sequences(x_train, maxlen=max_len)\n",
        "x_test = pad_sequences(x_test, maxlen = max_len)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEp1JbtAblhF"
      },
      "source": [
        "### 바다나우 어텐션"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGvd58Bbb51o"
      },
      "source": [
        "$$score(query, key)=V^T tanh(W_1 key + W_2 query) $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRfISJU0blE4"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-qG250Qb94W"
      },
      "source": [
        "class BahdanauAttention(tf.keras.Model):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = Dense(units)\n",
        "    self.W2 = Dense(units)\n",
        "    self.V = Dense(1)\n",
        "\n",
        "  def call(self, values, query):\n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "    ## query size (batch_size, hidden size)\n",
        "    ## hidden_with_time_axis (batch, 1 , hidden size)\n",
        "\n",
        "    score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "    # score == (batch size, max_length, 1)\n",
        "\n",
        "    attention_weights = tf.nn.softmax(score,axis=1)\n",
        "    # attention weights == (batch size, max_length, 1)\n",
        "\n",
        "    # context_vector after sum == (batch size, hidden size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhy1gLkqdr49"
      },
      "source": [
        "### 양방향 LSTM + 어텐션 메커니즘"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksiOllsZdWey"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Embedding, Bidirectional, LSTM, Concatenate, Dropout\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras import optimizers\n",
        "import os"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiNUOqBreEZu"
      },
      "source": [
        "sequence_input = Input(shape=(max_len,), dtype='int32')\n",
        "embedded_sequences = Embedding(vocab_size, 128, input_length=max_len, mask_zero=True)(sequence_input)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3jc8665fhN1"
      },
      "source": [
        "lstm = Bidirectional(LSTM(64, dropout=0.5, return_sequences=True))(embedded_sequences) # 64\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KyW00UEfj3a"
      },
      "source": [
        "lstm, forward_h, forward_c, backward_h, backward_c = Bidirectional(LSTM(64, dropout=0.5, return_sequences=True, return_state=True))(lstm)\n",
        "# 128 ([forward 64: backward 64])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0kYR53rfxJJ",
        "outputId": "23674a4c-8c5c-44fd-e4f6-8c1a40632858"
      },
      "source": [
        "print(lstm.shape, forward_h.shape, forward_c.shape, backward_h.shape, backward_c.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 500, 128) (None, 64) (None, 64) (None, 64) (None, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMf0esyzgY25"
      },
      "source": [
        "state_h = Concatenate()([forward_h, backward_h])\n",
        "state_c = Concatenate()([forward_c, backward_c])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m44D5uq9gsyW"
      },
      "source": [
        "attention = BahdanauAttention(64)\n",
        "context_vector, attention_weight = attention(lstm, state_h)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k5TbRi_g5Hh"
      },
      "source": [
        "dense1 = Dense(20, activation='relu')(context_vector)\n",
        "dropout = Dropout(0.5)(dense1)\n",
        "output = Dense(1, activation=\"sigmoid\")(dropout)\n",
        "model = Model(inputs = sequence_input, outputs=output)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUT3rGkKw1WI",
        "outputId": "ce29089e-b4cd-4cc2-9f95-0d934e5aecff"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 500)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 500, 128)     1280000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) (None, 500, 128)     98816       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_4 (Bidirectional) [(None, 500, 128), ( 98816       bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 128)          0           bidirectional_4[0][1]            \n",
            "                                                                 bidirectional_4[0][3]            \n",
            "__________________________________________________________________________________________________\n",
            "bahdanau_attention (BahdanauAtt ((None, 128), (None, 16577       bidirectional_4[0][0]            \n",
            "                                                                 concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 20)           2580        bahdanau_attention[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 20)           0           dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 1)            21          dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,496,810\n",
            "Trainable params: 1,496,810\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6maD-V7eiNAg"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ai0dJrjYi7W8",
        "outputId": "635c4a06-59cc-491e-b4c2-7334e18a7fcc"
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs=1, batch_size=256, validation_data = (x_test, y_test), verbose=1)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 936s 10s/step - loss: 0.1368 - accuracy: 0.9570 - val_loss: 0.3723 - val_accuracy: 0.8722\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQXkP_o0jF7x",
        "outputId": "a9e40e0d-9091-4e30-906e-b7a383ca03dd"
      },
      "source": [
        "print('\\n 테스트 정확도 : %.4f'%(model.evaluate(x_test, y_test)[1]))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 250s 320ms/step - loss: 0.3723 - accuracy: 0.8722\n",
            "\n",
            " 테스트 정확도 : 0.8722\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBedZesJxfOy"
      },
      "source": [
        "## seq2seq with attention 스페인-영어 번역기\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gn9oZ05FxqA1"
      },
      "source": [
        "### 데이터 준비하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUluIByJxFEM"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.ticker as ticker\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "import re\n",
        "import os\n",
        "import io"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UjI1ClJx8Hv",
        "outputId": "90f76554-f76f-4e0d-fc57-5d8eb316295b"
      },
      "source": [
        "path_to_zip = tf.keras.utils.get_file('spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip', extract=True)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "2646016/2638744 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-IjHueLx92K"
      },
      "source": [
        "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pJLgS9qyOYD",
        "outputId": "6ac8b3c1-8cce-49d4-9366-240bf4fb2bda"
      },
      "source": [
        "with open(path_to_file, 'r') as f:\n",
        "  raw = f.read().splitlines()\n",
        "\n",
        "print(\"Data Size: \", len(raw))\n",
        "print(\"Example :\")\n",
        "\n",
        "for sen in raw[0:100][::20]:print(\">>\",sen)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Size:  118964\n",
            "Example :\n",
            ">> Go.\tVe.\n",
            ">> Wait.\tEsperen.\n",
            ">> Hug me.\tAbrázame.\n",
            ">> No way!\t¡Ni cagando!\n",
            ">> Call me.\tLlamame.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0bjhOwGyoGr"
      },
      "source": [
        "### 데이터 정제"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmQid8OAyhxe"
      },
      "source": [
        "def preprocess_sentence(sentence, s_token=False, e_token=False):\n",
        "  sentence = sentence.lower().strip()\n",
        "\n",
        "  sentence = re.sub(r\"([?.!,])\", r\"\\1 \",sentence)\n",
        "  sentence = re.sub(r'[\" \"]+', \" \",sentence)\n",
        "  sentence = re.sub(r\"[^a-zA-Z?.!,]+\",\" \",sentence)\n",
        "\n",
        "  sentence = sentence.strip()\n",
        "\n",
        "  if s_token:\n",
        "    sentence = '<start> ' + sentence\n",
        "\n",
        "  if e_token:\n",
        "    sentence += ' <end>'\n",
        "\n",
        "  return sentence"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Y48viDXzeXF",
        "outputId": "919d29ab-afe4-47ed-cefb-f198935b2570"
      },
      "source": [
        "enc_corpus = []\n",
        "dec_corpus = []\n",
        "\n",
        "num_examples = 30000\n",
        "\n",
        "for pair in raw[:num_examples]:\n",
        "  eng, spa = pair.split(\"\\t\")\n",
        "\n",
        "  enc_corpus.append(preprocess_sentence(eng))\n",
        "  dec_corpus.append(preprocess_sentence(spa, s_token=True, e_token=True))\n",
        "\n",
        "print(\"English :\", enc_corpus[100])\n",
        "print(\"Spanish :\", dec_corpus[100])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English : go away!\n",
            "Spanish : <start> salga de aqu ! <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9Nw_d2B0LCL"
      },
      "source": [
        "### 데이터 전처리: 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh_wng5b0KYI"
      },
      "source": [
        "def tokenize(corpus):\n",
        "  tokenize = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "  tokenize.fit_on_texts(corpus)\n",
        "\n",
        "  tensor = tokenize.texts_to_sequences(corpus)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
        "  \n",
        "  return tensor, tokenize"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST-cWD0O0npn"
      },
      "source": [
        "enc_tensor, enc_tokenizer = tokenize(enc_corpus)\n",
        "dec_tensor, dec_tokenizer = tokenize(dec_corpus)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laTrAHnH1Ra1"
      },
      "source": [
        "### 훈련 데이터와 검증 데이터 분리하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzZ22IYt1Cwr"
      },
      "source": [
        "enc_train, enc_val, dec_train, dec_val = train_test_split(enc_tensor, dec_tensor, test_size=0.2)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c28vwCz71Ufx",
        "outputId": "b3a095db-b395-4c49-b356-c331397b523e"
      },
      "source": [
        "print('English Vocab Size : ', len(enc_tokenizer.index_word))\n",
        "print('Spanish Vocab Size : ', len(dec_tokenizer.index_word))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English Vocab Size :  7577\n",
            "Spanish Vocab Size :  12352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gStr-KCN2I9f"
      },
      "source": [
        "def call(self, h_enc, h_dec):\n",
        "    # h_enc == batch x length x units\n",
        "    # h_dec == batch x units\n",
        "\n",
        "    h_enc = self.w_enc(h_enc)\n",
        "    h_dec = tf.expand_dims(h_dec, 1)\n",
        "    h_dec = self.w_dec(h_dec)\n",
        "\n",
        "    score = self.w_com(tf.nn.tanh(h_dec+h_enc))\n",
        "\n",
        "    attn = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    context_vec = attn * h_enc\n",
        "    context_vec = tf.reduce_sum(context_vec, axis=1)\n",
        "    return context_vec, attn"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUeXgaX02n0J"
      },
      "source": [
        "![](https://aiffelstaticprd.blob.core.windows.net/media/images/GN-4-P-2.max-800x600.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8_YV8nR2lWT"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units):\n",
        "    super(Encoder, self).__init__()\n",
        "    # todo \n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(enc_units, return_sequences=True)\n",
        "\n",
        "  def call(self, x):\n",
        "    # todo\n",
        "    out = self.embedding(x)\n",
        "    out = self.gru(out)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45VDPdnm3Epa",
        "outputId": "e19e453c-ea18-4071-8b25-9acf932d9aec"
      },
      "source": [
        "BACTH_SIZE = 64\n",
        "src_vocab_size = len(enc_tokenizer.index_word) +1\n",
        "\n",
        "units = 1024\n",
        "embedding_dim = 512\n",
        "\n",
        "encoder = Encoder(src_vocab_size, embedding_dim, units)\n",
        "\n",
        "# sample input\n",
        "sequence_len = 30\n",
        "sample_enc = tf.random.uniform((BACTH_SIZE, sequence_len))\n",
        "sample_output = encoder(sample_enc)\n",
        "\n",
        "print('Encoder Output :', sample_output.shape)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder Output : (64, 30, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYNbUTWM9Jiq"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units):\n",
        "    super(Decoder, self).__init__()\n",
        "    ## Todo\n",
        "\n",
        "  def call(self, x, h_dec, enc_out):\n",
        "    ## Todo\n",
        "\n",
        "    return out, h_dec, attn"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qkERZdm9Lhh"
      },
      "source": [
        "BACTH_SIZE = 64\n",
        "tgt_vocab_size = len(dec_tokenizer.index_word) +1\n",
        "\n",
        "units = 1024\n",
        "embedding_dim = 512\n",
        "\n",
        "decoder = Decoder(tgt_vocab_size, embedding_dim, units)\n",
        "\n",
        "# sample input\n",
        "sample_state = tf.random.uniform((BATCH_SIZE, units))\n",
        "sample_logits, h_dec, attn = decoder(tf.random.uniform((BATCH_SIZE, 1)), sample_state, sample_output)\n",
        "\n",
        "print('Decoder Output :', sample_logits.shape)\n",
        "print('Decoder Hidden State :', h_dec.shape)\n",
        "print('Attention :', attn.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvmmWkgY9NEn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}