{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#폐암 수술 환자의 생존율 예측하기\n",
    "#딥러닝을 구동하는데 필요한 케라스 함수 호출\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "#필요한 라이브러리 불러오기 \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#실행할 때마다 같은 결과를 출력하기 위해 설정하는 부분\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#준비된 수술 환자 데이터를 불러오기\n",
    "Data_set = np.loadtxt(\"./ThoraricSurgery.csv\", delimiter=\",\")\n",
    "df = pd.DataFrame(Data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>293.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.88</td>\n",
       "      <td>2.16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.06</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.21</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1     2     3    4    5    6    7    8    9     10   11   12   13  \\\n",
       "0  293.0  1.0  3.80  2.80  0.0  0.0  0.0  0.0  0.0  0.0  12.0  0.0  0.0  0.0   \n",
       "1    1.0  2.0  2.88  2.16  1.0  0.0  0.0  0.0  1.0  1.0  14.0  0.0  0.0  0.0   \n",
       "2    8.0  2.0  3.19  2.50  1.0  0.0  0.0  0.0  1.0  0.0  11.0  0.0  0.0  1.0   \n",
       "3   14.0  2.0  3.98  3.06  2.0  0.0  0.0  0.0  1.0  1.0  14.0  0.0  0.0  0.0   \n",
       "4   17.0  2.0  2.21  1.88  0.0  0.0  1.0  0.0  0.0  0.0  12.0  0.0  0.0  0.0   \n",
       "\n",
       "    14   15    16   17  \n",
       "0  1.0  0.0  62.0  0.0  \n",
       "1  1.0  0.0  60.0  0.0  \n",
       "2  1.0  0.0  66.0  1.0  \n",
       "3  1.0  0.0  80.0  1.0  \n",
       "4  1.0  0.0  56.0  0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 470 entries, 0 to 469\n",
      "Data columns (total 18 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       470 non-null    float64\n",
      " 1   1       470 non-null    float64\n",
      " 2   2       470 non-null    float64\n",
      " 3   3       470 non-null    float64\n",
      " 4   4       470 non-null    float64\n",
      " 5   5       470 non-null    float64\n",
      " 6   6       470 non-null    float64\n",
      " 7   7       470 non-null    float64\n",
      " 8   8       470 non-null    float64\n",
      " 9   9       470 non-null    float64\n",
      " 10  10      470 non-null    float64\n",
      " 11  11      470 non-null    float64\n",
      " 12  12      470 non-null    float64\n",
      " 13  13      470 non-null    float64\n",
      " 14  14      470 non-null    float64\n",
      " 15  15      470 non-null    float64\n",
      " 16  16      470 non-null    float64\n",
      " 17  17      470 non-null    float64\n",
      "dtypes: float64(18)\n",
      "memory usage: 66.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>470.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>470.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>235.500000</td>\n",
       "      <td>3.095745</td>\n",
       "      <td>3.281638</td>\n",
       "      <td>4.568702</td>\n",
       "      <td>0.780851</td>\n",
       "      <td>0.065957</td>\n",
       "      <td>0.144681</td>\n",
       "      <td>0.065957</td>\n",
       "      <td>0.687234</td>\n",
       "      <td>0.165957</td>\n",
       "      <td>11.736170</td>\n",
       "      <td>0.074468</td>\n",
       "      <td>0.004255</td>\n",
       "      <td>0.017021</td>\n",
       "      <td>0.821277</td>\n",
       "      <td>0.004255</td>\n",
       "      <td>62.534043</td>\n",
       "      <td>0.148936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>135.821574</td>\n",
       "      <td>0.722309</td>\n",
       "      <td>0.871395</td>\n",
       "      <td>11.767857</td>\n",
       "      <td>0.535375</td>\n",
       "      <td>0.248472</td>\n",
       "      <td>0.352154</td>\n",
       "      <td>0.248472</td>\n",
       "      <td>0.464114</td>\n",
       "      <td>0.372439</td>\n",
       "      <td>0.702243</td>\n",
       "      <td>0.262811</td>\n",
       "      <td>0.065163</td>\n",
       "      <td>0.129488</td>\n",
       "      <td>0.383529</td>\n",
       "      <td>0.065163</td>\n",
       "      <td>8.706902</td>\n",
       "      <td>0.356405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.440000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>118.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>1.960000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>235.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.160000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>352.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.807500</td>\n",
       "      <td>3.080000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>470.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>86.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  470.000000  470.000000  470.000000  470.000000  470.000000  470.000000   \n",
       "mean   235.500000    3.095745    3.281638    4.568702    0.780851    0.065957   \n",
       "std    135.821574    0.722309    0.871395   11.767857    0.535375    0.248472   \n",
       "min      1.000000    1.000000    1.440000    0.960000    0.000000    0.000000   \n",
       "25%    118.250000    3.000000    2.600000    1.960000    0.000000    0.000000   \n",
       "50%    235.500000    3.000000    3.160000    2.400000    1.000000    0.000000   \n",
       "75%    352.750000    3.000000    3.807500    3.080000    1.000000    0.000000   \n",
       "max    470.000000    8.000000    6.300000   86.300000    2.000000    1.000000   \n",
       "\n",
       "               6           7           8           9           10          11  \\\n",
       "count  470.000000  470.000000  470.000000  470.000000  470.000000  470.000000   \n",
       "mean     0.144681    0.065957    0.687234    0.165957   11.736170    0.074468   \n",
       "std      0.352154    0.248472    0.464114    0.372439    0.702243    0.262811   \n",
       "min      0.000000    0.000000    0.000000    0.000000   11.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000   11.000000    0.000000   \n",
       "50%      0.000000    0.000000    1.000000    0.000000   12.000000    0.000000   \n",
       "75%      0.000000    0.000000    1.000000    0.000000   12.000000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000   14.000000    1.000000   \n",
       "\n",
       "               12          13          14          15          16          17  \n",
       "count  470.000000  470.000000  470.000000  470.000000  470.000000  470.000000  \n",
       "mean     0.004255    0.017021    0.821277    0.004255   62.534043    0.148936  \n",
       "std      0.065163    0.129488    0.383529    0.065163    8.706902    0.356405  \n",
       "min      0.000000    0.000000    0.000000    0.000000   21.000000    0.000000  \n",
       "25%      0.000000    0.000000    1.000000    0.000000   57.000000    0.000000  \n",
       "50%      0.000000    0.000000    1.000000    0.000000   62.000000    0.000000  \n",
       "75%      0.000000    0.000000    1.000000    0.000000   69.000000    0.000000  \n",
       "max      1.000000    1.000000    1.000000    1.000000   87.000000    1.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#환자의 기록과 수술 결과를 X와 Y로 구분하여 저장 \n",
    "X = Data_set[:,0:17]\n",
    "Y = Data_set[:,17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#딥러닝 구조를 결정(모델을 설정하고 실행)\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim = 17, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "47/47 [==============================] - 0s 790us/step - loss: 0.6482 - accuracy: 0.8128\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 0s 986us/step - loss: 0.4890 - accuracy: 0.8468\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 0s 756us/step - loss: 0.4416 - accuracy: 0.8511\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 0s 764us/step - loss: 0.4863 - accuracy: 0.8489\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 0s 742us/step - loss: 0.4430 - accuracy: 0.8532\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 0s 746us/step - loss: 0.4303 - accuracy: 0.8532\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4421 - accuracy: 0.8511\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 0s 745us/step - loss: 0.4363 - accuracy: 0.8489\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 0s 764us/step - loss: 0.4165 - accuracy: 0.8489\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 0s 786us/step - loss: 0.4317 - accuracy: 0.8489\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 0s 995us/step - loss: 0.4458 - accuracy: 0.8489\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4384 - accuracy: 0.8532\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 0s 776us/step - loss: 0.4651 - accuracy: 0.8532\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 0s 748us/step - loss: 0.4475 - accuracy: 0.8319\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 0s 764us/step - loss: 0.4934 - accuracy: 0.8255\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4472 - accuracy: 0.8447\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 0s 716us/step - loss: 0.4747 - accuracy: 0.8383\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 0s 763us/step - loss: 0.4488 - accuracy: 0.8468\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 0s 702us/step - loss: 0.4407 - accuracy: 0.8511\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 0s 745us/step - loss: 0.4380 - accuracy: 0.8511\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4331 - accuracy: 0.8532\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 0s 723us/step - loss: 0.4242 - accuracy: 0.8511\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 0s 714us/step - loss: 0.4183 - accuracy: 0.8532\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 0s 825us/step - loss: 0.4303 - accuracy: 0.8489\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 0s 729us/step - loss: 0.4246 - accuracy: 0.8511\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4335 - accuracy: 0.8532\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 0s 710us/step - loss: 0.4492 - accuracy: 0.8383\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 0s 691us/step - loss: 0.4241 - accuracy: 0.8532\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - 0s 772us/step - loss: 0.4212 - accuracy: 0.8532\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4136 - accuracy: 0.8511\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - 0s 726us/step - loss: 0.4389 - accuracy: 0.8511\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4188 - accuracy: 0.8553\n",
      "Epoch 33/100\n",
      "47/47 [==============================] - 0s 785us/step - loss: 0.4428 - accuracy: 0.8532\n",
      "Epoch 34/100\n",
      "47/47 [==============================] - 0s 738us/step - loss: 0.4103 - accuracy: 0.8489\n",
      "Epoch 35/100\n",
      "47/47 [==============================] - 0s 735us/step - loss: 0.4178 - accuracy: 0.8489\n",
      "Epoch 36/100\n",
      "47/47 [==============================] - 0s 740us/step - loss: 0.4136 - accuracy: 0.8532\n",
      "Epoch 37/100\n",
      "47/47 [==============================] - 0s 754us/step - loss: 0.4429 - accuracy: 0.8511\n",
      "Epoch 38/100\n",
      "47/47 [==============================] - 0s 685us/step - loss: 0.4258 - accuracy: 0.8489\n",
      "Epoch 39/100\n",
      "47/47 [==============================] - 0s 714us/step - loss: 0.4714 - accuracy: 0.8319\n",
      "Epoch 40/100\n",
      "47/47 [==============================] - 0s 756us/step - loss: 0.4041 - accuracy: 0.8574\n",
      "Epoch 41/100\n",
      "47/47 [==============================] - 0s 758us/step - loss: 0.4210 - accuracy: 0.8511\n",
      "Epoch 42/100\n",
      "47/47 [==============================] - 0s 789us/step - loss: 0.4418 - accuracy: 0.8447\n",
      "Epoch 43/100\n",
      "47/47 [==============================] - 0s 716us/step - loss: 0.4096 - accuracy: 0.8511\n",
      "Epoch 44/100\n",
      "47/47 [==============================] - 0s 672us/step - loss: 0.4032 - accuracy: 0.8511\n",
      "Epoch 45/100\n",
      "47/47 [==============================] - 0s 868us/step - loss: 0.4067 - accuracy: 0.8532\n",
      "Epoch 46/100\n",
      "47/47 [==============================] - 0s 765us/step - loss: 0.4030 - accuracy: 0.8532\n",
      "Epoch 47/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4132 - accuracy: 0.8447\n",
      "Epoch 48/100\n",
      "47/47 [==============================] - 0s 958us/step - loss: 0.4026 - accuracy: 0.8532\n",
      "Epoch 49/100\n",
      "47/47 [==============================] - 0s 768us/step - loss: 0.4082 - accuracy: 0.8511\n",
      "Epoch 50/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4097 - accuracy: 0.8511\n",
      "Epoch 51/100\n",
      "47/47 [==============================] - 0s 792us/step - loss: 0.4124 - accuracy: 0.8532\n",
      "Epoch 52/100\n",
      "47/47 [==============================] - 0s 684us/step - loss: 0.3972 - accuracy: 0.8553\n",
      "Epoch 53/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4128 - accuracy: 0.8489\n",
      "Epoch 54/100\n",
      "47/47 [==============================] - 0s 732us/step - loss: 0.4073 - accuracy: 0.8468\n",
      "Epoch 55/100\n",
      "47/47 [==============================] - 0s 722us/step - loss: 0.4110 - accuracy: 0.8532\n",
      "Epoch 56/100\n",
      "47/47 [==============================] - 0s 660us/step - loss: 0.3921 - accuracy: 0.8532\n",
      "Epoch 57/100\n",
      "47/47 [==============================] - 0s 688us/step - loss: 0.4091 - accuracy: 0.8532\n",
      "Epoch 58/100\n",
      "47/47 [==============================] - 0s 692us/step - loss: 0.3995 - accuracy: 0.8574\n",
      "Epoch 59/100\n",
      "47/47 [==============================] - 0s 806us/step - loss: 0.3985 - accuracy: 0.8532\n",
      "Epoch 60/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.3899 - accuracy: 0.8574\n",
      "Epoch 61/100\n",
      "47/47 [==============================] - 0s 660us/step - loss: 0.4041 - accuracy: 0.8553\n",
      "Epoch 62/100\n",
      "47/47 [==============================] - 0s 715us/step - loss: 0.4246 - accuracy: 0.8468\n",
      "Epoch 63/100\n",
      "47/47 [==============================] - 0s 697us/step - loss: 0.4068 - accuracy: 0.8532\n",
      "Epoch 64/100\n",
      "47/47 [==============================] - 0s 704us/step - loss: 0.4318 - accuracy: 0.8511\n",
      "Epoch 65/100\n",
      "47/47 [==============================] - 0s 814us/step - loss: 0.3902 - accuracy: 0.8553\n",
      "Epoch 66/100\n",
      "47/47 [==============================] - 0s 697us/step - loss: 0.4312 - accuracy: 0.8511\n",
      "Epoch 67/100\n",
      "47/47 [==============================] - 0s 750us/step - loss: 0.4164 - accuracy: 0.8489\n",
      "Epoch 68/100\n",
      "47/47 [==============================] - 0s 717us/step - loss: 0.4090 - accuracy: 0.8511\n",
      "Epoch 69/100\n",
      "47/47 [==============================] - 0s 818us/step - loss: 0.4020 - accuracy: 0.8511\n",
      "Epoch 70/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.3986 - accuracy: 0.8574\n",
      "Epoch 71/100\n",
      "47/47 [==============================] - 0s 693us/step - loss: 0.4027 - accuracy: 0.8511\n",
      "Epoch 72/100\n",
      "47/47 [==============================] - 0s 701us/step - loss: 0.4196 - accuracy: 0.8340\n",
      "Epoch 73/100\n",
      "47/47 [==============================] - 0s 718us/step - loss: 0.4019 - accuracy: 0.8532\n",
      "Epoch 74/100\n",
      "47/47 [==============================] - 0s 755us/step - loss: 0.3907 - accuracy: 0.8553\n",
      "Epoch 75/100\n",
      "47/47 [==============================] - 0s 725us/step - loss: 0.3890 - accuracy: 0.8553\n",
      "Epoch 76/100\n",
      "47/47 [==============================] - 0s 766us/step - loss: 0.4077 - accuracy: 0.8553\n",
      "Epoch 77/100\n",
      "47/47 [==============================] - 0s 737us/step - loss: 0.4178 - accuracy: 0.8426\n",
      "Epoch 78/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4080 - accuracy: 0.8553\n",
      "Epoch 79/100\n",
      "47/47 [==============================] - 0s 787us/step - loss: 0.4148 - accuracy: 0.8426\n",
      "Epoch 80/100\n",
      "47/47 [==============================] - 0s 793us/step - loss: 0.4019 - accuracy: 0.8468\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4057 - accuracy: 0.8532\n",
      "Epoch 82/100\n",
      "47/47 [==============================] - 0s 717us/step - loss: 0.4184 - accuracy: 0.8489\n",
      "Epoch 83/100\n",
      "47/47 [==============================] - 0s 651us/step - loss: 0.3944 - accuracy: 0.8532\n",
      "Epoch 84/100\n",
      "47/47 [==============================] - 0s 701us/step - loss: 0.4345 - accuracy: 0.8468\n",
      "Epoch 85/100\n",
      "47/47 [==============================] - 0s 743us/step - loss: 0.4050 - accuracy: 0.8489\n",
      "Epoch 86/100\n",
      "47/47 [==============================] - 0s 839us/step - loss: 0.3922 - accuracy: 0.8489\n",
      "Epoch 87/100\n",
      "47/47 [==============================] - 0s 810us/step - loss: 0.3976 - accuracy: 0.8511\n",
      "Epoch 88/100\n",
      "47/47 [==============================] - 0s 841us/step - loss: 0.3966 - accuracy: 0.8468\n",
      "Epoch 89/100\n",
      "47/47 [==============================] - 0s 869us/step - loss: 0.3886 - accuracy: 0.8468\n",
      "Epoch 90/100\n",
      "47/47 [==============================] - 0s 810us/step - loss: 0.3965 - accuracy: 0.8596\n",
      "Epoch 91/100\n",
      "47/47 [==============================] - 0s 698us/step - loss: 0.4220 - accuracy: 0.8532\n",
      "Epoch 92/100\n",
      "47/47 [==============================] - 0s 793us/step - loss: 0.4198 - accuracy: 0.8489\n",
      "Epoch 93/100\n",
      "47/47 [==============================] - 0s 688us/step - loss: 0.3953 - accuracy: 0.8511\n",
      "Epoch 94/100\n",
      "47/47 [==============================] - 0s 690us/step - loss: 0.3871 - accuracy: 0.8489\n",
      "Epoch 95/100\n",
      "47/47 [==============================] - 0s 685us/step - loss: 0.3864 - accuracy: 0.8574\n",
      "Epoch 96/100\n",
      "47/47 [==============================] - 0s 715us/step - loss: 0.4229 - accuracy: 0.8426\n",
      "Epoch 97/100\n",
      "47/47 [==============================] - 0s 683us/step - loss: 0.4149 - accuracy: 0.8447\n",
      "Epoch 98/100\n",
      "47/47 [==============================] - 0s 710us/step - loss: 0.3857 - accuracy: 0.8596\n",
      "Epoch 99/100\n",
      "47/47 [==============================] - 0s 692us/step - loss: 0.4051 - accuracy: 0.8532\n",
      "Epoch 100/100\n",
      "47/47 [==============================] - 0s 621us/step - loss: 0.3832 - accuracy: 0.8468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fa2cf74970>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#딥러닝 실행\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, Y, epochs=100, batch_size=10)\n",
    "#실행을 해보니 epochs 는 학습 횟수인것 같다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [2,4,6,8]\n",
    "y = [81,93,91,97]\n",
    "\n",
    "#x와 y의 평균 구하기\n",
    "mx = np.mean(x)\n",
    "my = np.mean(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#분모인 x의 각 원소와 x의 평균값들의 차를 제곱\n",
    "divisor = sum([(i - mx)**2 for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top(x, mx, y, my):\n",
    "    d = 0\n",
    "    for i in range(len(x)):\n",
    "        d += (x[i] - mx) * (y[i] - my)\n",
    "    return d\n",
    "dividend = top(x, mx, y, my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dividend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dividend / divisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = my - (mx*a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3\n",
      "79.0\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x의 평균값 : 5.0\n",
      "y의 평균값 : 90.5\n",
      "분모: 20.0\n",
      "분자: 46.0\n",
      "기울기 a= 2.3\n",
      "기울기 b= 79.0\n"
     ]
    }
   ],
   "source": [
    "#파이썬으로 최소 제곱법 구하기 MLS /method of least squares\n",
    "#위의 예제를 다시한번 실습\n",
    "import numpy as np\n",
    "#x값과 y 값\n",
    "x=[2, 4, 6, 8]\n",
    "y=[81, 93, 91, 97]\n",
    "\n",
    "#x와 y의 평균값\n",
    "mx = np.mean(x)\n",
    "my = np.mean(y)\n",
    "print(\"x의 평균값 :\", mx)\n",
    "print(\"y의 평균값 :\", my)\n",
    "\n",
    "#기울기 공식의 분모\n",
    "divisor = sum([(i-mx)**2 for i in x])\n",
    "\n",
    "#기울기 공식의 분자\n",
    "def top(x, mx, y, my):\n",
    "    d = 0\n",
    "    for i in range(len(x)):\n",
    "        d += (x[i] - mx) * (y[i]-my)\n",
    "    return d\n",
    "dividend = top(x, mx, y, my)\n",
    "print(\"분모:\", divisor)\n",
    "print(\"분자:\", dividend)\n",
    "\n",
    "#기울기와 y절편 구하기\n",
    "a = dividend / divisor\n",
    "b = my - (mx*a)\n",
    "\n",
    "#출력으로 확인\n",
    "print(\"기울기 a=\",a)\n",
    "print(\"기울기 b=\",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#선을 그린후 이선이 얼마나 잘 그려졌는지를 평가하여 조금씩 수정하는 방법\n",
    "#이 선의 오차를 평가하는 방법 \n",
    "#평균제곱오차 MSE / mean square error\n",
    "#선형회귀란 임의의 직선을 그어 이에 대한 평균 제곱 오차(MSE) 를 구하고,\n",
    "#이 값을 가장 작게 만들어주는 a와 b값을 찾아가는작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파이썬으로 구현하기.\n",
    "#임의로 정한 a와 y절편 b의 값이 각각 3과 76이라고 할때\n",
    "fake_a_b = [3, 76]\n",
    "\n",
    "#data 라는 리스트를 만들어 공부한 시간과 성적을 각각 짝을지어 저장\n",
    "#x리스트와 y리스트를 만들어 첫번째값을 x리스트에 두번쨰 값을 y리스트에\n",
    "\n",
    "data = [[2,81],[4,93],[6,91],[8,97]]\n",
    "x = [i[0] for i in data]\n",
    "y = [i[1] for i in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict() 라는 함수를 사용해 일차방정식 y= ax+b를 구현\n",
    "def predict(x):\n",
    "    return fake_a_b[0]*x + fake_a_b[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#평균제곱 오차 공식을 그대로 옮기면\n",
    "def mse(y, y_hat):\n",
    "    return ((y-y_hat) **2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mse 함수에 데이터를 대입하여 쵝=종값을 구하는 함수 mse_val을 만들자\n",
    "def mse_val(y, predict_result):\n",
    "    return mse(np.array(y), np.array(predict_result))\n",
    "#predict_result 에는 앞서 만든 predict()의 결과 값이 들어간다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "공부시간=2, 실제 점수=81, 예측 점수=82\n",
      "공부시간=4, 실제 점수=93, 예측 점수=88\n",
      "공부시간=6, 실제 점수=91, 예측 점수=94\n",
      "공부시간=8, 실제 점수=97, 예측 점수=100\n"
     ]
    }
   ],
   "source": [
    "#모든 x값을 predict()함수에 대입해 예측값을 구하고, 이 예측값과 실제 값을 통해 최종값을 출력하는 코드를 다음과 같이 작성\n",
    "#예측값이 들어갈 빈 리스트\n",
    "predict_result = []\n",
    "\n",
    "#모든 x값을 한번씩 대입하여\n",
    "for i in range(len(x)):\n",
    "    #그 결과에 해당하는 predict_result 리스트를 완성\n",
    "    predict_result.append(predict(x[i]))\n",
    "    print(\"공부시간=%.f, 실제 점수=%.f, 예측 점수=%.f\" %(x[i],y[i],predict(x[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "공부한 시간=2, 실제 점수=81, 예측 점수82\n",
      "공부한 시간=4, 실제 점수=93, 예측 점수88\n",
      "공부한 시간=6, 실제 점수=91, 예측 점수94\n",
      "공부한 시간=8, 실제 점수=97, 예측 점수100\n",
      "mse 최종값: 11.0\n"
     ]
    }
   ],
   "source": [
    "#복습\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#기울기 a와 y절편 b\n",
    "fake_a_b = [3, 76]\n",
    "\n",
    "#x, y의 데이터값\n",
    "data = [[2, 81], [4, 93], [6, 91], [8, 97]]\n",
    "x = [i[0] for i in data]\n",
    "y = [i[1] for i in data]\n",
    "\n",
    "#y = ax+b에 a와 b값을 대입하여 결과를 출력하는 함수\n",
    "def predict(x):\n",
    "    return fake_a_b[0]*x +fake_a_b[1]\n",
    "\n",
    "#MSE 함수\n",
    "def mse(y, y_hat):\n",
    "    return ((y-y_hat)**2).mean()\n",
    "\n",
    "#MSE 함수를 각 y 값에 대입하여 최종 값을 구하는 함수\n",
    "def mse_val(y, predict_result):\n",
    "    return mse(np.array(y), np.array(predict_result))\n",
    "\n",
    "#예측 값이 들어갈 빈 리스트\n",
    "predict_result = []\n",
    "\n",
    "#모든 x값을 한 번씩 대입하여\n",
    "for i in range(len(x)):\n",
    "    #predict_result 리스트를 완성\n",
    "    predict_result.append(predict(x[i]))\n",
    "    print(\"공부한 시간=%.f, 실제 점수=%.f, 예측 점수%.f\" % (x[i], y[i], predict(x[i])))\n",
    "    \n",
    "#최종 MSE 출력\n",
    "print(\"mse 최종값: \" + str(mse_val(predict_result,y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vp": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "title_cell": "VisualPython",
   "title_sidebar": "VisualPython",
   "vpPosition": {
    "height": "calc(100% - 180px)",
    "right": "10px",
    "top": "110px",
    "width": "50%"
   },
   "vp_cell": false,
   "vp_section_display": true,
   "vp_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
